{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char-rnn-tensorflow-js.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xynnect/MashineLearningGoogleColabs/blob/master/char_rnn_tensorflow_js.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU9nlueA4YZe",
        "colab_type": "text"
      },
      "source": [
        "# Using a neural network to generate startup names\n",
        "\n",
        "Author: Eliot Andres (http://twitter.com/eliotandres)\n",
        "\n",
        "Original notebooks: https://github.com/CSCfi/machine-learning-scripts/blob/master/slurm/keras-titles-rnn.py and https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:09:37.491915Z",
          "start_time": "2018-05-07T15:09:37.484986Z"
        },
        "id": "sZw8cLZL4YZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, RNN, SimpleRNNCell, SimpleRNN\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:02:38.485696Z",
          "start_time": "2018-05-07T15:02:38.425378Z"
        },
        "id": "MGRe3SMe4YZj",
        "colab_type": "code",
        "outputId": "4ed0ddc7-f95e-444a-f51f-0ed8ac2e3448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "companies = pd.read_csv('./companies.csv', header=None)\n",
        "companies.head()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hashplay Inc.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New Incentives</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GrabJobs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MediBookr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MelissaWithLove.co</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    0\n",
              "0       Hashplay Inc.\n",
              "1      New Incentives\n",
              "2            GrabJobs\n",
              "3           MediBookr\n",
              "4  MelissaWithLove.co"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:04:34.863079Z",
          "start_time": "2018-05-07T15:04:34.825877Z"
        },
        "id": "zK9E3eAr4YZr",
        "colab_type": "code",
        "outputId": "ea6d635f-dae2-40a9-de76-7956dee9ae3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "names = companies[0].values\n",
        "text = '\\n'.join(names)\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars: {}'.format(len(chars)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:04:42.782625Z",
          "start_time": "2018-05-07T15:04:42.778445Z"
        },
        "id": "SBvUEOrp4YZu",
        "colab_type": "code",
        "outputId": "3c467086-8c02-4b01-a3ee-fc82e437b306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('Corpus length:', len(text), 'lines:', len(names))\n",
        "print('First 10 lines:', names[:10])\n",
        "print('Number of unique chars:', len(chars))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 2560407 lines: 172488\n",
            "First 10 lines: ['Hashplay Inc.' 'New Incentives' 'GrabJobs' 'MediBookr'\n",
            " 'MelissaWithLove.co' 'Starting 11' 'The CarShare Guy' 'Allahabad Bank'\n",
            " 'Anlaiye' 'Any Time Loan']\n",
            "Number of unique chars: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:04:52.784444Z",
          "start_time": "2018-05-07T15:04:52.453686Z"
        },
        "id": "90grPh7G4YZx",
        "colab_type": "code",
        "outputId": "9233f061-ece6-4da4-fc85-b89bb80623f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 10\n",
        "step = 3\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))\n",
        "print('First 10 sequences and next chars:')\n",
        "for i in range(10):\n",
        "    print('[{}]:[{}]'.format(sentences[i], next_chars[i]))\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 853466\n",
            "First 10 sequences and next chars:\n",
            "[Hashplay I]:[n]\n",
            "[hplay Inc.]:[\n",
            "]\n",
            "[ay Inc.\n",
            "Ne]:[w]\n",
            "[Inc.\n",
            "New I]:[n]\n",
            "[.\n",
            "New Ince]:[n]\n",
            "[ew Incenti]:[v]\n",
            "[Incentives]:[\n",
            "]\n",
            "[entives\n",
            "Gr]:[a]\n",
            "[ives\n",
            "GrabJ]:[o]\n",
            "[s\n",
            "GrabJobs]:[\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:05:01.121805Z",
          "start_time": "2018-05-07T15:04:58.974929Z"
        },
        "id": "H_lw22AY4YZ2",
        "colab_type": "code",
        "outputId": "89b1e61b-9f19-4f49-8979-dbbdb2c2f531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Vectorization...')\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "print('Size of X: {:.2f} MB'.format(X.nbytes/1024/1024))\n",
        "print('Size of y: {:.2f} MB'.format(y.nbytes/1024/1024))\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n",
            "Size of X: 1220.89 MB\n",
            "Size of y: 122.09 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:07:03.894901Z",
          "start_time": "2018-05-07T15:07:03.708895Z"
        },
        "id": "8WilHGHl4YZ8",
        "colab_type": "code",
        "outputId": "54765c3c-d97b-409d-e392-de936ceea7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# ### Initialization\n",
        "# \n",
        "# Now we are ready to create a recurrent model.  Keras contains three types of recurrent layers:\n",
        "# \n",
        "#  * `SimpleRNN`, a fully-connected RNN where the output is fed back to input.\n",
        "#  * `LSTM`, the Long-Short Term Memory unit layer.\n",
        "#  * `GRU`, the Gated Recurrent Unit layer.\n",
        "# \n",
        "# See https://keras.io/layers/recurrent/ for more information.\n",
        "\n",
        "# Number of hidden units to use:\n",
        "nb_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Recurrent layers supported: SimpleRNN, LSTM, GRU:\n",
        "model.add(LSTM(nb_units, input_shape=(maxlen, len(chars))))\n",
        "\n",
        "# To stack multiple RNN layers, all RNN layers except the last one need\n",
        "# to have \"return_sequences=True\".  An example of using two RNN layers:\n",
        "#model.add(SimpleRNN(16,\n",
        "#                    input_shape=(maxlen, len(chars)),\n",
        "#                    return_sequences=True))\n",
        "#model.add(SimpleRNN(32))\n",
        "\n",
        "model.add(Dense(units=len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer)\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 64)                55040     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 150)               9750      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 150)               0         \n",
            "=================================================================\n",
            "Total params: 64,790\n",
            "Trainable params: 64,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71tv82toLSmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "ff9188b9-5c76-45db-f3e5-bf471199cd62"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Requirement already satisfied: tf-nightly-2.0-preview>=2.0.0.dev20190502 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.0.0.dev20190526)\n",
            "Requirement already satisfied: tensorflow-hub==0.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.9)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.1.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.8.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.14.0a20190526)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.11.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.14.0.dev2019052600)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T14:53:33.095997Z",
          "start_time": "2018-05-07T14:53:33.091837Z"
        },
        "id": "Wcfx9Bii4YZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:14:33.337110Z",
          "start_time": "2018-05-07T15:14:33.320548Z"
        },
        "id": "skInLEQq4YaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SampleResult(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "\n",
        "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "            generated = ''\n",
        "            sentence = text[start_index: start_index + maxlen]\n",
        "            generated += sentence\n",
        "            print()\n",
        "            print('----- Generating with diversity',\n",
        "                  diversity, 'seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(100):\n",
        "                x = np.zeros((1, maxlen, len(chars)))\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = self.model.predict(x, verbose=0)[0]\n",
        "                next_index = sample(preds, diversity)\n",
        "                next_char = indices_char[next_index]\n",
        "\n",
        "                generated += next_char\n",
        "                sentence = sentence[1:] + next_char\n",
        "\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "        print('\\n\\n')\n",
        "sample_callback = SampleResult()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:15:20.698027Z",
          "start_time": "2018-05-07T15:14:36.393734Z"
        },
        "id": "8KbKt2Wn4YaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5406
        },
        "outputId": "6b310005-eeaa-48c4-bcea-365d4b4caaad"
      },
      "source": [
        "history = model.fit(X, y, \n",
        "                        epochs=10, \n",
        "                        batch_size=512,\n",
        "                        verbose=2,\n",
        "                       callbacks=[sample_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 123s - loss: 2.2713\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"enewable R\"\n",
            "enewable Resources\n",
            "Compan Medical\n",
            "Prostate Software\n",
            "Start Communications\n",
            "Conter Services\n",
            "Contral Services\n",
            "Seal\n",
            "----- Generating with diversity 0.5 seed: \"enewable R\"\n",
            "enewable Resources International\n",
            "Accourter Technologies\n",
            "Starestriand Technologies\n",
            "Amplica\n",
            "Stark Medical Labs\n",
            "T\n",
            "----- Generating with diversity 1.0 seed: \"enewable R\"\n",
            "enewable Ramed Technologies\n",
            "IQ\n",
            "Timplon\n",
            "MEI\n",
            "LoFR\n",
            "Kot\n",
            "Quarami Technologies\n",
            "Aft Dosty Resayme\n",
            "ZiveBTART\n",
            "CodrySal\n",
            "\n",
            "----- Generating with diversity 1.2 seed: \"enewable R\"\n",
            "enewable RudenVeass\n",
            "Gaser NCCROV (NCEDISFVAB)\n",
            "DiCabremitia Sucwor.\n",
            "LendFrapTinbley\n",
            "NerEdecIRR Remicative\n",
            "Scher\n",
            "\n",
            "\n",
            "Epoch 2/10\n",
            " - 121s - loss: 2.0159\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"nd Urethan\"\n",
            "nd Urethan Corp.\n",
            "Active Technologies\n",
            "Complist Corp\n",
            "Compact\n",
            "Start Corporation\n",
            "Compacion Company\n",
            "Caster Technolo\n",
            "----- Generating with diversity 0.5 seed: \"nd Urethan\"\n",
            "nd Urethan Angage\n",
            "Netcorport\n",
            "Carevalit\n",
            "Social Systems\n",
            "Book Limited\n",
            "Internet Corp.\n",
            "Instrategie\n",
            "Artal Company\n",
            "Sa\n",
            "----- Generating with diversity 1.0 seed: \"nd Urethan\"\n",
            "nd Urethance\n",
            "CentCapital\n",
            "BSAG\n",
            "Natwide\n",
            "Electivak\n",
            "Bllux\n",
            "Lekmetas, Inc\n",
            "LOFOT\n",
            "Dagves\n",
            "Cloud Produces\n",
            "Oyluman cress\n",
            "\n",
            "----- Generating with diversity 1.2 seed: \"nd Urethan\"\n",
            "nd Urethanaportepho\n",
            "Jamfly PAV\n",
            "NixAPUG\n",
            "O2\n",
            "ALANPX\n",
            "Rthong\n",
            "Intre4Zae\n",
            "Jati\n",
            "Unico ICONH\n",
            "ykbergh Dhitisionne\n",
            "Crydlec\n",
            "\n",
            "\n",
            "Epoch 3/10\n",
            " - 122s - loss: 1.9686\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"porated\n",
            "Co\"\n",
            "porated\n",
            "Contric Software\n",
            "Sense Solutions\n",
            "Contron Solutions\n",
            "Advanced Inc.\n",
            "Contrace Solutions\n",
            "Sense Media\n",
            "Conste\n",
            "----- Generating with diversity 0.5 seed: \"porated\n",
            "Co\"\n",
            "porated\n",
            "Concoster Services\n",
            "Realogent\n",
            "Networks Insurance Services\n",
            "Golee Solutions\n",
            "Hourly Consulting\n",
            "Veron Solut\n",
            "----- Generating with diversity 1.0 seed: \"porated\n",
            "Co\"\n",
            "porated\n",
            "Complines\n",
            "Cleard Digital Systems\n",
            "Glopan\n",
            "MyPel\n",
            "Cowarda\n",
            "Onniza\n",
            "Sharx Company\n",
            "Omman\n",
            "QROL AM\n",
            "Brungok Bikes\n",
            "----- Generating with diversity 1.2 seed: \"porated\n",
            "Co\"\n",
            "porated\n",
            "Comparizans\n",
            "Wanduishnofg\n",
            "Gamrit\n",
            "VICcx\n",
            "PheroirShare Hotter Heartwair\n",
            "EXFread\n",
            "AdMAISE AS\n",
            "Brastro Bank Sy\n",
            "\n",
            "\n",
            "Epoch 4/10\n",
            " - 121s - loss: 1.9440\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"llo\n",
            "Groove\"\n",
            "llo\n",
            "Groovent Solutions\n",
            "Salestan Consulting\n",
            "Start Solutions\n",
            "Star Solutions\n",
            "Acceller\n",
            "Grander Solutions\n",
            "Star Stre\n",
            "----- Generating with diversity 0.5 seed: \"llo\n",
            "Groove\"\n",
            "llo\n",
            "Grooven Technology\n",
            "Sensen Research Solutions\n",
            "Control Corporation\n",
            "Surgerstrateg Group\n",
            "Omero\n",
            "Solora Media Lt\n",
            "----- Generating with diversity 1.0 seed: \"llo\n",
            "Groove\"\n",
            "llo\n",
            "GrooveScan\n",
            "Gramical Services\n",
            "Simplane Dap4Guo\n",
            "Gender Education\n",
            "Rood Everuly Lngin Arcalies Store\n",
            "Windathoo\n",
            "----- Generating with diversity 1.2 seed: \"llo\n",
            "Groove\"\n",
            "llo\n",
            "Grooveg Insuranme Midurant.an\n",
            "MotyBLS Corporation\n",
            "Leq. Seather\n",
            "Hitinglain WeMEBT)\n",
            "Benous Commerce\n",
            "Agrayda \n",
            "\n",
            "\n",
            "Epoch 5/10\n",
            " - 122s - loss: 1.9285\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"idodici\n",
            "Sm\"\n",
            "idodici\n",
            "Smart Software\n",
            "Soft Software\n",
            "Sanding Company\n",
            "Superal Media\n",
            "Finance Software\n",
            "Sander Communications\n",
            "Cont\n",
            "----- Generating with diversity 0.5 seed: \"idodici\n",
            "Sm\"\n",
            "idodici\n",
            "Smarton International\n",
            "Barra Apps\n",
            "Alliance\n",
            "Informatic\n",
            "Carter Media Group\n",
            "Selina Media\n",
            "Automarch Aviatio\n",
            "----- Generating with diversity 1.0 seed: \"idodici\n",
            "Sm\"\n",
            "idodici\n",
            "SmBle\n",
            "LR Hons\n",
            "203 Channet\n",
            "Sidebranco Software Agency Corporation\n",
            "Kilar Matages\n",
            "SociQuitforfim\n",
            "Bueroom\n",
            "\n",
            "----- Generating with diversity 1.2 seed: \"idodici\n",
            "Sm\"\n",
            "idodici\n",
            "Smite.com\n",
            "Medmos Realltics & xcuity International Technologies\n",
            "Equve SUSTCYBIAP Technologies\n",
            "K&CSPAX\n",
            "A\n",
            "\n",
            "\n",
            "Epoch 6/10\n",
            " - 121s - loss: 1.9180\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"ies\n",
            "Inters\"\n",
            "ies\n",
            "Intersactures\n",
            "Compan Strategies\n",
            "Star Corp\n",
            "The Stream Solutions\n",
            "Capital Services\n",
            "Capital\n",
            "Start Commercial S\n",
            "----- Generating with diversity 0.5 seed: \"ies\n",
            "Inters\"\n",
            "ies\n",
            "Intersactury\n",
            "Stality Media Corporation\n",
            "Attanty Scerce\n",
            "Kise Technology\n",
            "Production Services\n",
            "Cardical Service\n",
            "----- Generating with diversity 1.0 seed: \"ies\n",
            "Inters\"\n",
            "ies\n",
            "Interstext Ruchay\n",
            "Mojiands Technologies\n",
            "Aramwink.fo\n",
            "Unine Group\n",
            "Medicon Wireless RealtyAv\n",
            "REE Klane Wellni\n",
            "----- Generating with diversity 1.2 seed: \"ies\n",
            "Inters\"\n",
            "ies\n",
            "Intershancel\n",
            "Norpsta\n",
            "LunDopout\n",
            "Vision Hump\n",
            "Clurgni\n",
            "GuenChelaGak logidal Motictheson\n",
            "IsphorUre Solal.com\n",
            "CV\n",
            "\n",
            "\n",
            "Epoch 7/10\n",
            " - 121s - loss: 1.9103\n",
            "\n",
            "----- Generating with diversity 0.2 seed: \"io.it\n",
            "Devi\"\n",
            "io.it\n",
            "Devices\n",
            "Share Software\n",
            "Star Communications\n",
            "Connection\n",
            "Connection Services\n",
            "Care Medical Solutions\n",
            "Allera \n",
            "----- Generating with diversity 0.5 seed: \"io.it\n",
            "Devi\"\n",
            "io.it\n",
            "Devion Pharma\n",
            "Technosoft\n",
            "Expank\n",
            "Shippo\n",
            "Investor Corporation\n",
            "Digital Services\n",
            "Universe Technologies\n",
            "Tarin\n",
            "----- Generating with diversity 1.0 seed: \"io.it\n",
            "Devi\"\n",
            "io.it\n",
            "Devinek\n",
            "Genalyty\n",
            "Hytec\n",
            "Focalystuch\n",
            "CHEBAME\n",
            "Prylanktius\n",
            "Paragasional\n",
            "Cluble\n",
            "NixFable\n",
            "Papercel\n",
            "Tinisses Te\n",
            "----- Generating with diversity 1.2 seed: \"io.it\n",
            "Devi\"\n",
            "io.it\n",
            "Devisint,\n",
            "Insellos\n",
            "TcumMy\n",
            "Qchixs\n",
            "AGE Trace Intelipaten Sem Motoco Capital\n",
            "Devinewack Todx\n",
            "NiMemis Waily\n",
            "\n",
            "\n",
            "\n",
            "Epoch 8/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:15:20.698394Z",
          "start_time": "2018-05-07T15:15:16.103Z"
        },
        "id": "nAhF0H_D4YaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./model-startup.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-05-07T15:15:20.698728Z",
          "start_time": "2018-05-07T15:15:16.289Z"
        },
        "id": "IG_O77Uf4YaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import tensorflow.contrib.eager as tfe\n",
        "\n",
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(model, './jsmodel/')\n",
        "\n",
        "# tensorflowjs_converter.save_keras_model(model, './jsmodel/')\n",
        "# tfjs.converters.save_keras_model(model, './jsmodel/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAvsE8QO4YaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}